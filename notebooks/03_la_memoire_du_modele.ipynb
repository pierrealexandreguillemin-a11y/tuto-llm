{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "> **Rappel** : clique sur une cellule grise, puis **Shift + Entree** pour l'executer.\n> Execute les cellules **dans l'ordre** de haut en bas.\n\n---\n\n# Leçon 3 : La mémoire du modèle\n\n## Le problème de la mémoire courte\n\nDans les leçons précédentes, notre modèle ne regardait que la **dernière lettre**.\nC'est comme essayer de deviner la fin d'une phrase en n'écoutant que le dernier mot.\n\nExemple : après les lettres 'salame', le modèle ne sait pas si on est dans\n\"**salame**che\" ou \"**salame**nce\" -- pourtant la suite est très différente !\n\nSolution : donner une **mémoire** au modèle. On appelle ça les **embeddings**."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "_exercices_faits = set()\n",
    "_NB_TOTAL = 3\n",
    "\n",
    "\n",
    "def verifier(num_exercice, condition, message_ok, message_aide=\"\"):\n",
    "    \"\"\"Valide un exercice avec feedback HTML vert/rouge + compteur.\"\"\"\n",
    "    try:\n",
    "        _result = bool(condition)\n",
    "    except Exception:\n",
    "        _result = False\n",
    "    if _result:\n",
    "        _exercices_faits.add(num_exercice)\n",
    "        n = len(_exercices_faits)\n",
    "        barre = \"\\U0001f7e9\" * n + \"\\u2b1c\" * (_NB_TOTAL - n)\n",
    "        display(\n",
    "            HTML(\n",
    "                f'<div style=\"padding:10px;background:#d4edda;border-left:5px solid #28a745;'\n",
    "                f'margin:8px 0;border-radius:4px;font-family:system-ui,-apple-system,sans-serif\">'\n",
    "                f\"\\u2705 <b>{message_ok}</b><br>\"\n",
    "                f'<span style=\"color:#555\">Progression : {barre} {n}/{_NB_TOTAL}</span></div>'\n",
    "            )\n",
    "        )\n",
    "        if n == _NB_TOTAL:\n",
    "            display(\n",
    "                HTML(\n",
    "                    '<div style=\"padding:12px;background:linear-gradient(135deg,#3949ab,#6a1b9a);'\n",
    "                    \"color:white;border-radius:8px;text-align:center;font-family:system-ui,-apple-system,sans-serif;\"\n",
    "                    'font-size:1.2em;margin:8px 0\">\\U0001f3c6 <b>Bravo ! Toutes les activites de cette lecon sont terminees !</b></div>'\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        display(\n",
    "            HTML(\n",
    "                f'<div style=\"padding:10px;background:#fff3cd;border-left:5px solid #ffc107;'\n",
    "                f'margin:8px 0;border-radius:4px;font-family:system-ui,-apple-system,sans-serif\">'\n",
    "                f\"\\U0001f4a1 <b>{message_aide}</b></div>\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def exercice(numero, titre, consigne, observation=\"\"):\n",
    "    \"\"\"Affiche la banniere d'exercice.\"\"\"\n",
    "\n",
    "    def _style_code(text):\n",
    "        return text.replace(\n",
    "            \"<code>\",\n",
    "            '<code style=\"font-size:0.95em;background:#bbdefb;'\n",
    "            'padding:1px 5px;border-radius:3px;font-family:monospace;\">',\n",
    "        )\n",
    "\n",
    "    obs = \"\"\n",
    "    if observation:\n",
    "        obs = (\n",
    "            f'<div style=\"margin-top:6px;color:#555;font-size:0.92em;\">'\n",
    "            f\"<b>Ce que tu vas voir\\u00a0:</b> {_style_code(observation)}</div>\"\n",
    "        )\n",
    "    display(\n",
    "        HTML(\n",
    "            f'<div style=\"border-left:5px solid #1565c0;background:#e8f0fe;'\n",
    "            f\"padding:12px 16px; margin:4px 0 10px 0; border-radius:0 8px 8px 0;\"\n",
    "            f'font-family:system-ui,-apple-system,sans-serif; font-size:0.95em;\">'\n",
    "            f'<b style=\"color:#0d47a1;\">Exercice\\u00a0{numero} \\u2014 {titre}</b><br>'\n",
    "            f\"{_style_code(consigne)}{obs}</div>\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def afficher_embeddings(embeddings, alphabet, titre=\"Embeddings\"):\n",
    "    \"\"\"Affiche les embeddings sous forme de table HTML coloree.\"\"\"\n",
    "    rows = \"\"\n",
    "    for i, lettre in enumerate(alphabet[:15]):  # max 15 pour lisibilite\n",
    "        cells_html = \"\"\n",
    "        for val in embeddings[i][:8]:  # max 8 dims\n",
    "            r = int(max(0, min(255, 128 + val * 200)))\n",
    "            g = int(max(0, min(255, 128 - abs(val) * 100)))\n",
    "            b = int(max(0, min(255, 128 - val * 200)))\n",
    "            cells_html += f'<td style=\"padding:3px 6px;background:rgb({r},{g},{b});color:white;text-align:center;font-size:0.8em;border:1px solid #ddd\">{val:.2f}</td>'\n",
    "        rows += f'<tr><th style=\"padding:3px 8px;font-size:1em\">{lettre}</th>{cells_html}</tr>'\n",
    "    display(\n",
    "        HTML(\n",
    "            f'<!-- tuto-viz --><div style=\"margin:8px 0;overflow-x:auto\"><b>{titre}</b>'\n",
    "            f'<table style=\"border-collapse:collapse;margin-top:4px\">{rows}</table>'\n",
    "            f'<div style=\"margin-top:4px;color:#555;font-size:0.8em\">Chaque ligne = une lettre, chaque colonne = une dimension du vecteur</div></div>'\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def afficher_barres(valeurs, etiquettes, titre=\"Probabilites\"):\n",
    "    \"\"\"Affiche des barres horizontales HTML.\"\"\"\n",
    "    rows = \"\"\n",
    "    max_val = max(valeurs) if valeurs else 1\n",
    "    for etiq, val in zip(etiquettes, valeurs, strict=False):\n",
    "        pct = val / max_val * 100 if max_val > 0 else 0\n",
    "        rows += (\n",
    "            f'<tr><td style=\"padding:3px 8px;font-weight:bold;font-size:1em\">{etiq}</td>'\n",
    "            f'<td style=\"padding:3px;width:300px\"><div style=\"background:linear-gradient(90deg,#3949ab,#6a1b9a);'\n",
    "            f'width:{max(pct, 2):.0f}%;height:20px;border-radius:4px\"></div></td>'\n",
    "            f'<td style=\"padding:3px 8px;font-size:0.9em\">{val:.0%}</td></tr>'\n",
    "        )\n",
    "    display(\n",
    "        HTML(\n",
    "            f'<!-- tuto-viz --><div style=\"margin:8px 0\"><b>{titre}</b>'\n",
    "            f'<table style=\"border-collapse:collapse;margin-top:4px\">{rows}</table></div>'\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Outils de visualisation charges !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Les embeddings : transformer des lettres en nombres\n\nL'idée : chaque lettre est représentée par une **liste de nombres** (un vecteur).\n\nPar exemple :\n- 'a' -> [0.3, -0.1, 0.8]\n- 'b' -> [-0.5, 0.4, 0.2]\n\nCes nombres ne sont pas choisis à la main : le modèle les **apprend** pendant\nl'entraînement. Les lettres qui se comportent de façon similaire auront\ndes nombres proches."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "\n",
    "# Notre alphabet\n",
    "alphabet = list(\".abcdefghijklmnopqrstuvwxyz\")\n",
    "char_to_id = {c: i for i, c in enumerate(alphabet)}\n",
    "id_to_char = {i: c for i, c in enumerate(alphabet)}\n",
    "vocab_size = len(alphabet)\n",
    "\n",
    "print(f\"Taille du vocabulaire : {vocab_size} caractères\")\n",
    "print(\n",
    "    f\"Exemples : 'a' = {char_to_id['a']}, 'z' = {char_to_id['z']}, '.' = {char_to_id['.']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créons les embeddings : chaque lettre = un vecteur de taille EMBED_DIM\n",
    "EMBED_DIM = 8\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "# Initialisation aléatoire (le modèle apprendra les bonnes valeurs)\n",
    "embeddings = [\n",
    "    [random.gauss(0, 0.5) for _ in range(EMBED_DIM)] for _ in range(vocab_size)\n",
    "]\n",
    "\n",
    "print(f\"Embedding de 'a' : {[f'{x:.2f}' for x in embeddings[char_to_id['a']]]}\")\n",
    "print(f\"Embedding de 'b' : {[f'{x:.2f}' for x in embeddings[char_to_id['b']]]}\")\n",
    "print()\n",
    "print(\"Pour l'instant ces nombres sont aléatoires.\")\n",
    "print(\"Après entraînement, les lettres similaires auront des vecteurs proches.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercice(\n",
    "    1,\n",
    "    \"Change la dimension\",\n",
    "    \"Change <code>EMBED_DIM_test</code> ci-dessous (essaie 4 ou 16), puis <b>Shift + Entree</b>.\",\n",
    "    \"Plus la dimension est grande, plus le modele a de parametres.\",\n",
    ")\n",
    "\n",
    "# ==== MODIFIE ICI ====\n",
    "EMBED_DIM_test = 8  # <-- Essaie 4 (petit) ou 16 (grand) !\n",
    "# ======================\n",
    "\n",
    "print(f\"Avec EMBED_DIM = {EMBED_DIM_test} :\")\n",
    "print(f\"  Chaque lettre = {EMBED_DIM_test} nombres\")\n",
    "print(f\"  3 lettres de contexte = 3 x {EMBED_DIM_test} = {3 * EMBED_DIM_test} nombres\")\n",
    "if EMBED_DIM_test <= 4:\n",
    "    print(\"  -> Petit : le modele a peu d'information sur chaque lettre.\")\n",
    "elif EMBED_DIM_test >= 16:\n",
    "    print(\"  -> Grand : plus d'information, mais plus de calculs !\")\n",
    "\n",
    "# Validation exercice 1\n",
    "verifier(\n",
    "    1,\n",
    "    EMBED_DIM_test != 8,\n",
    "    f\"Bien joue ! Avec {EMBED_DIM_test} dimensions, le vecteur de contexte fait {3 * EMBED_DIM_test} nombres.\",\n",
    "    \"Change EMBED_DIM_test pour une autre valeur, par exemple 4 ou 16.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Regarder plusieurs lettres en arrière\n\nMaintenant, au lieu de regarder 1 seule lettre, on va regarder les\n**3 dernières lettres** (notre \"fenêtre de contexte\").\n\nOn **concatène** (met bout à bout) leurs embeddings pour avoir une image\ncomplète du contexte."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 3\n",
    "\n",
    "\n",
    "def get_context_vector(mot, position, embeddings):\n",
    "    \"\"\"Récupère les embeddings des 3 dernières lettres et les concatène.\"\"\"\n",
    "    vecteur = []\n",
    "    for i in range(CONTEXT_SIZE):\n",
    "        pos = position - CONTEXT_SIZE + i\n",
    "        if pos < 0:\n",
    "            # Avant le début du mot, on utilise le padding (.)\n",
    "            char_id = char_to_id[\".\"]\n",
    "        else:\n",
    "            char_id = char_to_id[mot[pos]]\n",
    "        vecteur.extend(embeddings[char_id])\n",
    "    return vecteur\n",
    "\n",
    "\n",
    "# Exemple : pour prédire la 5e lettre de \"pikachu\"\n",
    "mot = \".pikachu.\"\n",
    "position = 4  # on veut prédire 'a' (position 4)\n",
    "contexte = get_context_vector(mot, position, embeddings)\n",
    "\n",
    "print(f\"Mot : '{mot}'\")\n",
    "print(f\"Pour prédire la lettre en position {position} ('{mot[position]}'),\")\n",
    "print(\n",
    "    f\"on regarde les {CONTEXT_SIZE} lettres précédentes : '{mot[max(0, position - CONTEXT_SIZE) : position]}'\"\n",
    ")\n",
    "print(f\"Vecteur de contexte : {len(contexte)} nombres ({CONTEXT_SIZE} x {EMBED_DIM})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercice(\n",
    "    2,\n",
    "    \"Change le contexte\",\n",
    "    \"Change <code>context_test</code> ci-dessous (essaie 1 ou 5).\",\n",
    "    \"Avec un contexte de 1, le modele oublie tout (comme la lecon 2).\",\n",
    ")\n",
    "\n",
    "# ==== MODIFIE ICI ====\n",
    "context_test = 3  # <-- Essaie 1 (comme la lecon 2) ou 5 (plus de memoire) !\n",
    "# ======================\n",
    "\n",
    "taille_vecteur = context_test * EMBED_DIM\n",
    "print(f\"Avec CONTEXT_SIZE = {context_test} :\")\n",
    "print(f\"  Le modele regarde {context_test} lettre(s) en arriere\")\n",
    "print(\n",
    "    f\"  Vecteur de contexte = {context_test} x {EMBED_DIM} = {taille_vecteur} nombres\"\n",
    ")\n",
    "if context_test == 1:\n",
    "    print(\"  -> Pareil que la lecon 2 : 1 seule lettre !\")\n",
    "elif context_test >= 5:\n",
    "    print(\"  -> Beaucoup de memoire, mais plus long a entrainer.\")\n",
    "\n",
    "# Validation exercice 2\n",
    "verifier(\n",
    "    2,\n",
    "    context_test != 3,\n",
    "    f\"Super ! Avec un contexte de {context_test}, le modele utilise {context_test * EMBED_DIM} nombres.\",\n",
    "    \"Change context_test pour une autre valeur, par exemple 1 ou 5.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Un mini réseau de neurones ---\n",
    "# On passe le contexte dans un réseau simple pour obtenir les probabilités.\n",
    "# [contexte: 24 nombres] --> [couche] --> [27 scores] --> [probas]\n",
    "\n",
    "INPUT_DIM = CONTEXT_SIZE * EMBED_DIM  # 3 * 8 = 24\n",
    "\n",
    "# Les poids de notre couche (une matrice 24 x 27)\n",
    "W = [[random.gauss(0, 0.3) for _ in range(vocab_size)] for _ in range(INPUT_DIM)]\n",
    "b = [0.0] * vocab_size  # biais\n",
    "\n",
    "\n",
    "def forward(contexte, W, b):\n",
    "    \"\"\"Passe le contexte dans le réseau pour obtenir des scores.\"\"\"\n",
    "    scores = list(b)  # copie du biais\n",
    "    for j in range(vocab_size):\n",
    "        for i in range(INPUT_DIM):\n",
    "            scores[j] += contexte[i] * W[i][j]\n",
    "    return scores\n",
    "\n",
    "\n",
    "def softmax(scores):\n",
    "    \"\"\"Transforme les scores en probabilités (entre 0 et 1, somme = 1).\"\"\"\n",
    "    max_s = max(scores)\n",
    "    exps = [math.exp(s - max_s) for s in scores]\n",
    "    total = sum(exps)\n",
    "    return [e / total for e in exps]\n",
    "\n",
    "\n",
    "# Test\n",
    "scores = forward(contexte, W, b)\n",
    "probas = softmax(scores)\n",
    "\n",
    "# Top 5 prédictions pour la lettre après 'pik' dans 'pikachu'\n",
    "top5 = sorted(range(vocab_size), key=lambda i: -probas[i])[:5]\n",
    "print(\"Prédictions (avant entraînement) pour la lettre après 'pik' :\")\n",
    "for idx in top5:\n",
    "    print(f\"  '{id_to_char[idx]}' : {probas[idx]:.1%}\")\n",
    "print(\"\\n  (C'est du hasard pour l'instant - il faut entraîner !)\")\n",
    "\n",
    "# Visualisation des predictions\n",
    "afficher_barres(\n",
    "    [probas[idx] for idx in top5],\n",
    "    [id_to_char[idx] for idx in top5],\n",
    "    titre=\"Top 5 predictions apres 'pik' (avant entrainement)\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement\n",
    "pokemons = [\n",
    "    \"arcanin\",\n",
    "    \"bulbizarre\",\n",
    "    \"carapuce\",\n",
    "    \"dracaufeu\",\n",
    "    \"ectoplasma\",\n",
    "    \"evoli\",\n",
    "    \"felinferno\",\n",
    "    \"gardevoir\",\n",
    "    \"goupix\",\n",
    "    \"lokhlass\",\n",
    "    \"lucario\",\n",
    "    \"metamorph\",\n",
    "    \"mewtwo\",\n",
    "    \"noctali\",\n",
    "    \"pikachu\",\n",
    "    \"rondoudou\",\n",
    "    \"ronflex\",\n",
    "    \"salameche\",\n",
    "    \"togepi\",\n",
    "    \"voltali\",\n",
    "]\n",
    "\n",
    "vitesse = 0.01\n",
    "\n",
    "print(\"Entraînement avec contexte de 3 lettres...\")\n",
    "print()\n",
    "\n",
    "for epoch in range(100):\n",
    "    loss_totale = 0\n",
    "    nb = 0\n",
    "\n",
    "    for pokemon in pokemons:\n",
    "        mot = \".\" + pokemon + \".\"\n",
    "        for pos in range(1, len(mot)):\n",
    "            cible = char_to_id[mot[pos]]\n",
    "\n",
    "            # Forward\n",
    "            ctx = get_context_vector(mot, pos, embeddings)\n",
    "            scores = forward(ctx, W, b)\n",
    "            probas = softmax(scores)\n",
    "\n",
    "            # Loss\n",
    "            loss_totale += -math.log(probas[cible] + 1e-10)\n",
    "            nb += 1\n",
    "\n",
    "            # Gradient simplifié pour W et b\n",
    "            for j in range(vocab_size):\n",
    "                grad = probas[j] - (1 if j == cible else 0)\n",
    "                b[j] -= vitesse * grad\n",
    "                for i in range(INPUT_DIM):\n",
    "                    W[i][j] -= vitesse * grad * ctx[i]\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"  Epoch {epoch:3d} | Loss : {loss_totale / nb:.3f}\")\n",
    "\n",
    "print(f\"  Epoch {epoch:3d} | Loss : {loss_totale / nb:.3f}\")\n",
    "\n",
    "# Visualisation des embeddings apres entrainement\n",
    "afficher_embeddings(embeddings, alphabet, titre=\"Embeddings apres entrainement\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générer avec le modèle entraîné\n",
    "def generer(n=10):\n",
    "    resultats = []\n",
    "    for _ in range(n):\n",
    "        mot = \".\"\n",
    "        for _ in range(20):\n",
    "            ctx = get_context_vector(mot, len(mot), embeddings)\n",
    "            scores = forward(ctx, W, b)\n",
    "            probas = softmax(scores)\n",
    "            idx = random.choices(range(vocab_size), weights=probas, k=1)[0]\n",
    "            if idx == char_to_id[\".\"]:\n",
    "                break\n",
    "            mot += id_to_char[idx]\n",
    "        if len(mot) > 1:\n",
    "            resultats.append(mot[1:].capitalize())\n",
    "    return resultats\n",
    "\n",
    "\n",
    "print(\"Pokémon générés (avec contexte de 3 lettres) :\")\n",
    "print()\n",
    "for p in generer(10):\n",
    "    print(f\"  {p}\")\n",
    "\n",
    "print()\n",
    "print(\"Mieux qu'avant ! Le modèle 'comprend' des combinaisons de lettres.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercice(\n",
    "    3,\n",
    "    \"Genere des Pokemon\",\n",
    "    \"Change <code>nombre</code> ci-dessous (essaie 30).\",\n",
    "    \"Compare avec la lecon 2 : les noms sont-ils meilleurs ?\",\n",
    ")\n",
    "\n",
    "# ==== MODIFIE ICI ====\n",
    "nombre = 10  # <-- Mets 30 ici !\n",
    "# ======================\n",
    "\n",
    "print(f\"Generation de {nombre} Pokemon :\")\n",
    "print()\n",
    "for i, nom in enumerate(generer(nombre)):\n",
    "    print(f\"  {i + 1}. {nom}\")\n",
    "\n",
    "# Validation exercice 3\n",
    "verifier(\n",
    "    3,\n",
    "    nombre != 10,\n",
    "    f\"Genial ! Tu as genere {nombre} Pokemon.\",\n",
    "    \"Change nombre pour une autre valeur, par exemple 30.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Ce qu'on a appris\n\n- Les **embeddings** transforment des lettres en nombres que le modèle peut manipuler\n- Un **contexte** plus large (3 lettres au lieu de 1) donne de meilleurs résultats\n- Un **réseau de neurones** (même simple) combine le contexte pour faire des prédictions\n\n### Et ensuite ?\n\nNotre modèle regarde toujours une fenêtre fixe de 3 lettres. Et s'il pouvait\n**choisir** quelles lettres sont importantes, même si elles sont loin ?\nC'est exactement ce que fait le **mécanisme d'attention** -- le cœur des GPT.\n\n---\n*Prochaine leçon : [04 - L'attention](04_lattention.ipynb)*"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Sources (ISO 42001)\n",
    "\n",
    "- **Embeddings et réseau feed-forward** : [microgpt.py](https://gist.github.com/karpathy/8627fe009c40f57531cb18360106ce95) — Andrej Karpathy, section token/position embeddings\n",
    "- **Architecture du contexte par concaténation** : [Vidéo \"Let's build GPT\"](https://www.youtube.com/watch?v=kCc8FmEb1nY) — Andrej Karpathy (2023)\n",
    "- **Concept d'embedding spaces** : [3Blue1Brown - Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) — Grant Sanderson\n",
    "- **Dataset Pokémon** : (c) Nintendo / Creatures Inc. / GAME FREAK inc., usage éducatif. Source : [PokéAPI](https://pokeapi.co/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
