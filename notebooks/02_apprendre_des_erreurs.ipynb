{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "> **Rappel** : clique sur une cellule grise, puis **Shift + Entree** pour l'executer.\n> Execute les cellules **dans l'ordre** de haut en bas.\n\n---\n\n# Leçon 2 : Apprendre de ses erreurs\n\n## Le secret de l'IA : se tromper, corriger, recommencer\n\nImagine que tu apprends à lancer une balle dans un panier :\n1. Tu lances -> tu rates à droite\n2. Tu corriges un peu à gauche\n3. Tu relances -> plus près !\n4. Tu continues jusqu'à marquer\n\nL'IA fait **exactement** pareil. Elle fait une prédiction, regarde si c'est\nbon, et ajuste. Ça s'appelle **l'entraînement**."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "_exercices_faits = set()\n",
    "_NB_TOTAL = 3\n",
    "\n",
    "\n",
    "def verifier(num_exercice, condition, message_ok, message_aide=\"\"):\n",
    "    \"\"\"Valide un exercice avec feedback HTML vert/rouge + compteur.\"\"\"\n",
    "    try:\n",
    "        _result = bool(condition)\n",
    "    except Exception:\n",
    "        _result = False\n",
    "    if _result:\n",
    "        _exercices_faits.add(num_exercice)\n",
    "        n = len(_exercices_faits)\n",
    "        barre = \"\\U0001f7e9\" * n + \"\\u2b1c\" * (_NB_TOTAL - n)\n",
    "        display(\n",
    "            HTML(\n",
    "                f'<div style=\"padding:10px;background:#d4edda;border-left:5px solid #28a745;'\n",
    "                f'margin:8px 0;border-radius:4px;font-family:system-ui,-apple-system,sans-serif\">'\n",
    "                f\"\\u2705 <b>{message_ok}</b><br>\"\n",
    "                f'<span style=\"color:#555\">Progression : {barre} {n}/{_NB_TOTAL}</span></div>'\n",
    "            )\n",
    "        )\n",
    "        if n == _NB_TOTAL:\n",
    "            display(\n",
    "                HTML(\n",
    "                    '<div style=\"padding:12px;background:linear-gradient(135deg,#3949ab,#6a1b9a);'\n",
    "                    \"color:white;border-radius:8px;text-align:center;font-family:system-ui,-apple-system,sans-serif;\"\n",
    "                    'font-size:1.2em;margin:8px 0\">\\U0001f3c6 <b>Bravo ! Toutes les activites de cette lecon sont terminees !</b></div>'\n",
    "                )\n",
    "            )\n",
    "    else:\n",
    "        display(\n",
    "            HTML(\n",
    "                f'<div style=\"padding:10px;background:#fff3cd;border-left:5px solid #ffc107;'\n",
    "                f'margin:8px 0;border-radius:4px;font-family:system-ui,-apple-system,sans-serif\">'\n",
    "                f\"\\U0001f4a1 <b>{message_aide}</b></div>\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def exercice(numero, titre, consigne, observation=\"\"):\n",
    "    \"\"\"Affiche la banniere d'exercice.\"\"\"\n",
    "\n",
    "    def _style_code(text):\n",
    "        return text.replace(\n",
    "            \"<code>\",\n",
    "            '<code style=\"font-size:0.95em;background:#bbdefb;'\n",
    "            'padding:1px 5px;border-radius:3px;font-family:monospace;\">',\n",
    "        )\n",
    "\n",
    "    obs = \"\"\n",
    "    if observation:\n",
    "        obs = (\n",
    "            f'<div style=\"margin-top:6px;color:#555;font-size:0.92em;\">'\n",
    "            f\"<b>Ce que tu vas voir\\u00a0:</b> {_style_code(observation)}</div>\"\n",
    "        )\n",
    "    display(\n",
    "        HTML(\n",
    "            f'<div style=\"border-left:5px solid #1565c0;background:#e8f0fe;'\n",
    "            f\"padding:12px 16px; margin:4px 0 10px 0; border-radius:0 8px 8px 0;\"\n",
    "            f'font-family:system-ui,-apple-system,sans-serif; font-size:0.95em;\">'\n",
    "            f'<b style=\"color:#0d47a1;\">Exercice\\u00a0{numero} \\u2014 {titre}</b><br>'\n",
    "            f\"{_style_code(consigne)}{obs}</div>\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def afficher_evolution_loss(pertes, titre=\"Courbe de loss\"):\n",
    "    \"\"\"Affiche la loss sous forme de barres verticales HTML avec degrade.\"\"\"\n",
    "    if not pertes:\n",
    "        return\n",
    "    max_loss = max(pertes)\n",
    "    min_loss = min(pertes)\n",
    "    bars = \"\"\n",
    "    n = len(pertes)\n",
    "    bar_w = max(4, min(20, 600 // n))\n",
    "    for i, loss in enumerate(pertes):\n",
    "        h = int((loss / max_loss) * 120) if max_loss > 0 else 0\n",
    "        ratio = (loss - min_loss) / (max_loss - min_loss) if max_loss > min_loss else 0\n",
    "        r = int(220 * ratio + 30)\n",
    "        g = int(180 * (1 - ratio) + 50)\n",
    "        bars += (\n",
    "            f'<div style=\"display:inline-block;width:{bar_w}px;vertical-align:bottom;'\n",
    "            f'margin:0 1px;height:{h}px;background:rgb({r},{g},60);border-radius:2px 2px 0 0\" '\n",
    "            f'title=\"Epoch {i}: {loss:.3f}\"></div>'\n",
    "        )\n",
    "    display(\n",
    "        HTML(\n",
    "            f'<!-- tuto-viz --><div style=\"margin:8px 0\"><b>{titre}</b>'\n",
    "            f'<div style=\"display:flex;align-items:flex-end;height:140px;padding:8px;'\n",
    "            f'background:#f8f9fa;border-radius:4px;margin-top:4px\">{bars}</div>'\n",
    "            f'<div style=\"display:flex;justify-content:space-between;color:#555;font-size:0.8em;margin-top:2px\">'\n",
    "            f\"<span>Epoch 0 (loss={pertes[0]:.2f})</span><span>Epoch {len(pertes) - 1} (loss={pertes[-1]:.2f})</span></div></div>\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Outils de visualisation charges !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Étape 1 : Mesurer l'erreur\n\nD'abord, il faut un moyen de dire **à quel point** le modèle s'est trompé.\nOn appelle ça la **loss** (perte en anglais).\n\n- Loss haute = le modèle se trompe beaucoup\n- Loss basse = le modèle devine bien"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Imaginons que le modèle prédit les probabilités suivantes\n",
    "# pour la lettre qui suit 'p' dans 'pikachu' :\n",
    "\n",
    "prediction = {\n",
    "    \"i\": 0.6,  # 60% -> bonne réponse !\n",
    "    \"a\": 0.2,  # 20%\n",
    "    \"e\": 0.15,  # 15%\n",
    "    \"o\": 0.05,  # 5%\n",
    "}\n",
    "\n",
    "# La bonne réponse est 'i'\n",
    "bonne_reponse = \"i\"\n",
    "\n",
    "# La loss = à quel point on est surpris par la bonne réponse\n",
    "# Si on avait dit 100% pour 'i', la surprise serait de 0 (parfait !)\n",
    "# Si on avait dit 1% pour 'i', la surprise serait énorme\n",
    "\n",
    "loss = -math.log(prediction[bonne_reponse])\n",
    "print(\n",
    "    f\"Le modèle donnait {prediction[bonne_reponse]:.0%} de chance à '{bonne_reponse}'\"\n",
    ")\n",
    "print(f\"Loss = {loss:.2f}\")\n",
    "print()\n",
    "\n",
    "# Comparons avec une mauvaise prédiction\n",
    "mauvaise_prediction = {\"i\": 0.05, \"a\": 0.7, \"e\": 0.2, \"o\": 0.05}\n",
    "loss_mauvaise = -math.log(mauvaise_prediction[bonne_reponse])\n",
    "print(\n",
    "    f\"Si le modèle n'avait donné que {mauvaise_prediction[bonne_reponse]:.0%} à '{bonne_reponse}'...\"\n",
    ")\n",
    "print(f\"Loss = {loss_mauvaise:.2f}  (beaucoup plus haut = beaucoup plus faux)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercice(\n",
    "    1,\n",
    "    \"Joue avec la perte\",\n",
    "    \"Change <code>ma_prediction</code> ci-dessous (essaie 0.9 ou 0.01), puis <b>Shift + Entree</b>.\",\n",
    "    \"Plus ta prediction est loin de la bonne reponse, plus la loss monte.\",\n",
    ")\n",
    "\n",
    "# ==== MODIFIE ICI ====\n",
    "ma_prediction = 0.6  # <-- Change cette valeur ! Essaie 0.9 ou 0.01\n",
    "# ======================\n",
    "\n",
    "ma_loss = -math.log(ma_prediction)\n",
    "print(f\"Si le modele donne {ma_prediction:.0%} de chance a la bonne reponse :\")\n",
    "print(f\"  Loss = {ma_loss:.2f}\")\n",
    "if ma_prediction > 0.8:\n",
    "    print(\"  -> Tres bien ! Le modele est confiant et a raison.\")\n",
    "elif ma_prediction < 0.1:\n",
    "    print(\"  -> Enorme loss ! Le modele s'est beaucoup trompe.\")\n",
    "else:\n",
    "    print(\"  -> Moyen. Le modele peut encore s'ameliorer.\")\n",
    "\n",
    "# Validation exercice 1\n",
    "verifier(\n",
    "    1,\n",
    "    ma_prediction != 0.6,\n",
    "    f\"Bien joue ! Avec {ma_prediction:.0%}, la loss est {ma_loss:.2f}.\",\n",
    "    \"Change ma_prediction pour une autre valeur, par exemple 0.9 ou 0.01.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Étape 2 : Les poids du modèle ---\n",
    "# Un modèle = une collection de nombres (les \"poids\").\n",
    "# Ces nombres déterminent les prédictions. Entraîner = trouver les bons nombres.\n",
    "\n",
    "import math\n",
    "import random\n",
    "\n",
    "# On crée un mini-modèle : juste des scores pour chaque paire de lettres\n",
    "# Au début, les scores sont aléatoires -> le modèle ne sait rien\n",
    "\n",
    "alphabet = list(\"abcdefghijklmnopqrstuvwxyz.\")\n",
    "\n",
    "# Scores aléatoires (les \"poids\" du modèle)\n",
    "random.seed(42)\n",
    "poids = {}\n",
    "for a in alphabet:\n",
    "    poids[a] = {}\n",
    "    for b in alphabet:\n",
    "        poids[a][b] = random.uniform(-1, 1)\n",
    "\n",
    "\n",
    "def calculer_probas(poids, lettre):\n",
    "    \"\"\"Transforme les scores en probabilités (softmax).\"\"\"\n",
    "    scores = poids[lettre]\n",
    "    # L'exponentielle rend tous les scores positifs\n",
    "    exps = {b: math.exp(scores[b]) for b in scores}\n",
    "    total = sum(exps.values())\n",
    "    return {b: exps[b] / total for b in scores}\n",
    "\n",
    "\n",
    "# Au début, les probas sont quasi uniformes (le modèle devine au hasard)\n",
    "p = calculer_probas(poids, \".\")\n",
    "lettres_debut = sorted(p.items(), key=lambda x: -x[1])[:5]\n",
    "print(\"Au début, le modèle pense que les Pokémon commencent par :\")\n",
    "for lettre, prob in lettres_debut:\n",
    "    print(f\"  '{lettre}' : {prob:.1%}\")\n",
    "print(\"\\n  -> C'est n'importe quoi ! Il faut l'entraîner.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Étape 3 : Entraînement\n\nL'algorithme est simple :\n1. Prendre un nom de Pokémon d'entraînement\n2. Le modèle fait sa prédiction\n3. On calcule la loss (l'erreur)\n4. On **ajuste les poids** pour réduire la loss\n5. Recommencer\n\nL'étape 4 s'appelle la **descente de gradient**. C'est comme ajuster ton\ntir au panier un petit peu à chaque essai."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pokemons = [\n",
    "    \"arcanin\",\n",
    "    \"bulbizarre\",\n",
    "    \"carapuce\",\n",
    "    \"dracaufeu\",\n",
    "    \"ectoplasma\",\n",
    "    \"evoli\",\n",
    "    \"felinferno\",\n",
    "    \"gardevoir\",\n",
    "    \"goupix\",\n",
    "    \"lokhlass\",\n",
    "    \"lucario\",\n",
    "    \"metamorph\",\n",
    "    \"mewtwo\",\n",
    "    \"noctali\",\n",
    "    \"pikachu\",\n",
    "    \"rondoudou\",\n",
    "    \"ronflex\",\n",
    "    \"salameche\",\n",
    "    \"togepi\",\n",
    "    \"voltali\",\n",
    "]\n",
    "\n",
    "# Vitesse d'apprentissage : de combien on ajuste à chaque fois\n",
    "# Trop grand = on dépasse, trop petit = on apprend trop lentement\n",
    "vitesse = 0.1  # <-- Change cette valeur ! Essaie 0.01 ou 0.5\n",
    "nb_epochs = 50  # <-- Change cette valeur ! Essaie 10 ou 200\n",
    "\n",
    "print(\"Entraînement...\")\n",
    "print()\n",
    "\n",
    "_historique_loss = []\n",
    "\n",
    "for epoch in range(nb_epochs):\n",
    "    loss_totale = 0\n",
    "    nb = 0\n",
    "\n",
    "    for pokemon in pokemons:\n",
    "        mot = \".\" + pokemon + \".\"\n",
    "        for i in range(len(mot) - 1):\n",
    "            lettre = mot[i]\n",
    "            cible = mot[i + 1]\n",
    "\n",
    "            # 1. Prédiction\n",
    "            probas = calculer_probas(poids, lettre)\n",
    "\n",
    "            # 2. Loss\n",
    "            loss_totale += -math.log(probas[cible] + 1e-10)\n",
    "            nb += 1\n",
    "\n",
    "            # 3. Ajuster les poids (gradient simplifié)\n",
    "            for b in alphabet:\n",
    "                if b == cible:\n",
    "                    # La bonne réponse : augmenter son score\n",
    "                    poids[lettre][b] += vitesse * (1 - probas[b])\n",
    "                else:\n",
    "                    # Les mauvaises réponses : baisser leur score\n",
    "                    poids[lettre][b] -= vitesse * probas[b]\n",
    "\n",
    "    _historique_loss.append(loss_totale / nb)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"  Epoch {epoch:2d} | Loss moyenne : {loss_totale / nb:.3f}\")\n",
    "\n",
    "print(f\"  Epoch {epoch:2d} | Loss moyenne : {loss_totale / nb:.3f}\")\n",
    "print()\n",
    "print(\"La loss baisse = le modèle s'améliore !\")\n",
    "\n",
    "# Visualisation de la courbe de loss\n",
    "afficher_evolution_loss(\n",
    "    _historique_loss, titre=\"Evolution de la loss pendant l'entrainement\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercice(\n",
    "    2,\n",
    "    \"Compare les vitesses\",\n",
    "    \"Change <code>vitesse_test</code> ci-dessous (essaie 0.01, 0.1, 0.5, 2.0).\",\n",
    "    \"Une vitesse trop grande fait exploser la loss, trop petite la fait stagner.\",\n",
    ")\n",
    "\n",
    "# ==== MODIFIE ICI ====\n",
    "vitesse_test = 0.5  # <-- Change cette valeur ! Essaie 0.01, 0.1, 0.5, 2.0\n",
    "# ======================\n",
    "\n",
    "# On repart de zero avec des poids aleatoires\n",
    "random.seed(123)\n",
    "poids_test = {}\n",
    "for a in alphabet:\n",
    "    poids_test[a] = {}\n",
    "    for b in alphabet:\n",
    "        poids_test[a][b] = random.uniform(-1, 1)\n",
    "\n",
    "# Mini-entrainement de 5 epochs avec cette vitesse\n",
    "for epoch in range(5):\n",
    "    loss_t = 0\n",
    "    nb_t = 0\n",
    "    for pokemon in pokemons:\n",
    "        mot = \".\" + pokemon + \".\"\n",
    "        for i in range(len(mot) - 1):\n",
    "            probas_t = calculer_probas(poids_test, mot[i])\n",
    "            loss_t += -math.log(probas_t[mot[i + 1]] + 1e-10)\n",
    "            nb_t += 1\n",
    "            for b in alphabet:\n",
    "                if b == mot[i + 1]:\n",
    "                    poids_test[mot[i]][b] += vitesse_test * (1 - probas_t[b])\n",
    "                else:\n",
    "                    poids_test[mot[i]][b] -= vitesse_test * probas_t[b]\n",
    "    print(f\"  Epoch {epoch} | vitesse={vitesse_test} | Loss : {loss_t / nb_t:.3f}\")\n",
    "\n",
    "# Validation exercice 2\n",
    "verifier(\n",
    "    2,\n",
    "    vitesse_test != 0.5,\n",
    "    f\"Bien ! Tu as teste la vitesse {vitesse_test}.\",\n",
    "    \"Change vitesse_test pour une autre valeur, par exemple 0.01 ou 2.0.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voyons maintenant ce que le modèle a appris :\n",
    "p = calculer_probas(poids, \".\")\n",
    "lettres_debut = sorted(p.items(), key=lambda x: -x[1])[:5]\n",
    "print(\"Après entraînement, les Pokémon commencent par :\")\n",
    "for lettre, prob in lettres_debut:\n",
    "    print(f\"  '{lettre}' : {prob:.1%}\")\n",
    "print()\n",
    "print(\"C'est plus logique ! (c, m, g, e, r sont des débuts courants)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Générons des noms de Pokémon avec le modèle entraîné\n",
    "def generer(poids, n=10):\n",
    "    resultats = []\n",
    "    for _ in range(n):\n",
    "        pokemon = \"\"\n",
    "        lettre = \".\"\n",
    "        for _ in range(20):  # max 20 lettres\n",
    "            p = calculer_probas(poids, lettre)\n",
    "            choix = list(p.keys())\n",
    "            probs = list(p.values())\n",
    "            lettre = random.choices(choix, weights=probs, k=1)[0]\n",
    "            if lettre == \".\":\n",
    "                break\n",
    "            pokemon += lettre\n",
    "        if pokemon:\n",
    "            resultats.append(pokemon.capitalize())\n",
    "    return resultats\n",
    "\n",
    "\n",
    "print(\"Noms de Pokémon inventés après entraînement :\")\n",
    "for p in generer(poids, 10):\n",
    "    print(f\"  {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exercice(\n",
    "    3,\n",
    "    \"Genere des Pokemon\",\n",
    "    \"Change <code>nombre</code> ci-dessous (essaie 50).\",\n",
    "    \"Certains noms vont ressembler a de vrais Pokemon !\",\n",
    ")\n",
    "\n",
    "# ==== MODIFIE ICI ====\n",
    "nombre = 10  # <-- Mets 50 ici !\n",
    "# ======================\n",
    "\n",
    "print(f\"Generation de {nombre} Pokemon :\")\n",
    "print()\n",
    "for i, nom in enumerate(generer(poids, nombre)):\n",
    "    print(f\"  {i + 1}. {nom}\")\n",
    "\n",
    "# Validation exercice 3\n",
    "verifier(\n",
    "    3,\n",
    "    nombre != 10,\n",
    "    f\"Genial ! Tu as genere {nombre} Pokemon.\",\n",
    "    \"Change nombre pour une autre valeur, par exemple 50.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Ce qu'on a appris\n\n- La **loss** mesure à quel point le modèle se trompe\n- Les **poids** sont les nombres que le modèle ajuste pour apprendre\n- L'**entraînement** = ajuster les poids pour réduire la loss, encore et encore\n- Même un modèle simple s'améliore avec l'entraînement !\n\n### Limite\n\nNotre modèle ne regarde encore que **1 lettre en arrière**.\nDans la prochaine leçon, on va lui donner une **mémoire** pour qu'il\nse souvienne de plusieurs lettres à la fois.\n\n---\n*Prochaine leçon : [03 - La mémoire du modèle](03_la_memoire_du_modele.ipynb)*"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Sources (ISO 42001)\n",
    "\n",
    "- **Cross-entropy loss et descente de gradient** : [microgpt.py](https://gist.github.com/karpathy/8627fe009c40f57531cb18360106ce95) — Andrej Karpathy, lignes implémentant le backward pass\n",
    "- **Analogie du gradient comme correction** : [Vidéo \"Let's build GPT\"](https://www.youtube.com/watch?v=kCc8FmEb1nY) — Andrej Karpathy (2023)\n",
    "- **Visualisation de la descente de gradient** : [3Blue1Brown - Gradient descent](https://www.youtube.com/watch?v=IHZwWFHWa-w) — Grant Sanderson\n",
    "- **Dataset Pokémon** : (c) Nintendo / Creatures Inc. / GAME FREAK inc., usage éducatif. Source : [PokéAPI](https://pokeapi.co/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
